{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dc0f8a",
   "metadata": {},
   "source": [
    "This is an alternative approach to the one in the \"Query a pdf document - FRTB-SA regulation\" notebook saved in the same folder\n",
    "\n",
    "The one in this notebook uses the langchain library and Pinecone vector store  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840bcce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavlo\\anaconda3\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f9b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_DOC = \"data/d352.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb14a4b",
   "metadata": {},
   "source": [
    "This analysis is based on similar approaches i found online, e.g. \n",
    "https://bennycheung.github.io/ask-a-book-questions-with-langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7125a",
   "metadata": {},
   "source": [
    "### Extract the Book Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e90b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredPDFLoader(PDF_DOC)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79f708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 297,193 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content):,} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f942441",
   "metadata": {},
   "source": [
    "### Split Book into Smaller Chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81098487",
   "metadata": {},
   "source": [
    "We will be dividing the loaded PDF document into smaller “pages” of 1000 characters each. The reason for doing this is to provide contextual information to OpenAI when we ask it a question. This is because OpenAI embeddings work best with shorter pieces of text. Instead of making OpenAI read the entire book every time we ask a question, it is more efficient and cost-effective to give it a smaller section of relevant information to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8520ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 381 documents\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753a1b0",
   "metadata": {},
   "source": [
    "###  Build Semantic Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d398211",
   "metadata": {},
   "source": [
    "Create embeddings of our documents to get ready for semantic search. We store these vectors online in a Pinecone vector store so we can add more books to our corpus and not have to re-read the PDFs each time. We also assign a book namespace in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514a1c1",
   "metadata": {},
   "source": [
    "The user needs to create a Pinecone key, env and index\n",
    "An example of how to create an index is here: https://www.youtube.com/watch?v=h0DHDp1FbmQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea26f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db3eba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "# the user must have created their own pinecone key & env\n",
    "# this is an example of how to do this: https://www.youtube.com/watch?v=h0DHDp1FbmQ\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  \n",
    "    environment=os.environ[\"PINECONE_API_ENV\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87909a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"langchain1\" # use the name of the Pinecone index you have created here\n",
    "namespace = \"book\"\n",
    "\n",
    "docsearch = Pinecone.from_texts(\n",
    "  [t.page_content for t in texts], embeddings,\n",
    "  index_name=index_name, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420067d",
   "metadata": {},
   "source": [
    "## Ask questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf448d79",
   "metadata": {},
   "source": [
    "After we built the index, we are ready to query those docs to get our answer back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edb210ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0., openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6198d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the definition of the Trading Desk?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5e5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A trading desk for the purposes of the regulatory capital framework is an unambiguously defined group of traders or trading accounts. Each individual trader or trading account must be assigned to only one trading desk. The desk must have a clear reporting line to senior management and must have a clear and formal compensation policy linked to its pre-established objectives.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = docsearch.similarity_search(query,\n",
    "  include_metadata=True, namespace=namespace)\n",
    "\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f046182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
